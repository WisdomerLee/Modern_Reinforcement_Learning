Monte Carlo Prediction

주어진 기본 모델 없이 학습하는 알고리즘은 reward를 계속 추적하고 확인하며 최적의 reward를 얻는 방향을 배우게 된다
(하나의 행동에 대한)에피스드가 끝날 때마다 해당 reward를 기록
state value, action value를 계산하는 함수를 업데이트

value function을 계산하고 보다 많은 value를 얻도록하여 반복
이것은 병렬처리가 가능함!!!

First vs Every Visit MC
reward의 추적은 visiting state 다음에 받게 됨
처음 방문할 때만 reward를 얻으면 > First visit MC
매번 방문할 때마다 reward를 얻으면 > Every visit MC
