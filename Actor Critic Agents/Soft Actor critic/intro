learning에 ddpg, td3를 적용
hyperparameter tuning을 보다 적게 쓸 것
고등 수학이 많이 필요하나 실제 적용에 우선순위를 두고 논문 분석

ddpg, td3는 학습률에 있어서 유의미한 차이를 줄 수 있을지는 몰라도
hyper parameter 설정에 매우 많은 신경을 기울여야 함
hyper parameter tuning에서 처음 값을 설정이나, 그 뒤에 gradient minimum 등을 찾아낼 때 등등...
최소한 3개의 neural network가 필요함 :actor, critic, value network
cost function을 개선해야 함
policy : probability distribution, 샘플 얻기...등에 쓰임

entropy 개념을 reward scailing에 도입
replay buffer를 learn function에 적용

policy에 normal distribution
entropy : reward의 scale factor에 적용
actor network의 output 평균, sigma : normal distribution으로
sample distribution : get action > pytorch의 log prob
reparameterization : pytorch 문서의 distributions항목
two critic networks : actor/value의 cost function이 최소인 값을 얻음

다른 방법들 중에서
pybullet version을 활용
