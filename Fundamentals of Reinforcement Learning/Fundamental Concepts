기본

Agent, Environment가 주어지고 reward, penalty를 이용하여 학습을 시킴

Agent의 행동을 학습하게 하는 것인데

Agent가 주어진 환경에서 활동을 하면(동작을 취하면) 상태가 바뀌고 그에 대한 보상을 주어주게 됨
상태, 행동, 보상이 agent가 주변 환경을 확인하며 동작하는 것..

Agent가 동작을 바꾸기 위해서는 무엇이 필요한가?

Environment는 무엇??
Agent가 갖다두어야 할 목적의 위치(혹은 행동해야 할 위치 등등)와 그 보상들을 포함한 개념

행동들의 분류(Classification (action))는 상태 변화를 가져옴(state transition)

state vs environment
state: weight sensor를 읽어오는 것

Agent의 행동으로 new weight가 생성되면
모든 가능한 상태들의 모음(set of all possible states)이 상태 공간(state space)
사람의 간섭은 영향이 없음
시간 딜레이는 신경쓰지 않음

지도 학습(Supervised Learning) : 
특정 조건들을 주어주고 해당 환경에서 행동하였을 때의 보상을 처리할 경우??
조건에 맞는 상황들의 정보들이 필요함

Agent 정의
Agent : software
memory of states, actions, and reward
상태, 행동, 보상을 모두 기억함
결정을 내리는 프로세스가 있음
인격화 하지 말 것
software와 hardware는 같은 공간에 있지 않음
보상을 강화시키는 방향으로 나아감
Algorithm(Q learning)으로 보상을 최대로 만들려 함

Actions
구분됨(좋은것 나쁜것 모르는 것)
모든 가능한 행동들의 모음 (set of all possible actions): 행동 공간 (action space)
몇몇 문제들은 연속적인 행동들을 가질 때가 있음
Q learning은 구분되는 행동들을 학습할 때 쓰임

Agent가 주어진 환경에서 어떤(최적의) 행동을 하도록 유도 하는 것이 강화 학습의 목적

상태는 오직 바로 직전의 상태와 행동에 의존함
