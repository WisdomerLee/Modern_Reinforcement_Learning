Learning vs Maximizing Rewards
어떻게 가르치고 어떻게 보상을 최대화 시킬 것??
Opportunity cost of greed : 탐욕 소비의 기회

Explore-Exploit
제일 잘 알려진 행동 : greed
덜 최적화된 행동 : exploration
그런데 다른 것을 찾아서 이동하는 행동으로 오히려 보상이 -가 된다면?? > 그러면 탐험하는 행동을 멈추게 될 것

아주 빠른 접근 방법:
각 step마다 -1의 페널티를 주는 것
혹은 winning의 reward 자체를 0으로!
negtive reward를 최소로 줄이는 것!

예를 들어 미로를 탈출하는 가장 빠른 길을 찾는 방식이라던가..

initial estimate : 0, greedy policy를 선택
그런데.... 어떻게 최적화를 할 것인가???

disppointment :실망을 이용하기
disappoint <> back to hope 두 상태를 이용하여
exploration  success
탐험하게 하고 성공하였을 때 disappointment가 보다 덜한 선택을 하여 최적화

이런 방식의 해결책을
optimistic initial values라고 함

또다른 해결책
Epsilon Greedy
행동 선택에 대한 파라미터를 갖고 있음

이 파라미터는 랜덤한 숫자로 지정되어
매 행동마다 랜덤한 숫자를 골라 고른 숫자가 epsilon보다 작으면: 아무 행동이나, epsilon보다 크면 : 탐욕 행동(greedy action)

모든 가능한 상태를 전부 체험하게 하고 epsilon은 시간에 따라 점점 줄어들게 됨
처음에는 아무 행동이나 무작위로 진행하지만 시간이 지남에 따라 greedy action이 더 많이 동작하게 됨
epsilon이 줄어드는 것은 선형적으로 로그, 혹은 지수함수로 줄어들 수도 있음
가장 중요한 것은 epsilon이 제한된 상태로 남아있어야 하는 것
